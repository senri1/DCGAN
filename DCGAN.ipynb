{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt \n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "PATH = './'\n",
    "CODE_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 3\n",
    "BIAS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y) , (_,_) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_CLASSES = 10\n",
    "# cifar10_classes = {\"airplane\":0, \"automobile\":1, \"bird\":2, \"cat\":3, \"deer\":4, \n",
    "#                    \"dog\":5, \"frog\":6, \"horse\":7, \"ship\":8, \"truck\":9}\n",
    "# generate_class = \"automobile\"\n",
    "\n",
    "# class_num = cifar10_classes[generate_class]\n",
    "# class_indices = np.where(y == class_num)[0]\n",
    "# x = x[class_indices,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[1,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.moveaxis(x,3,1)\n",
    "x = x.astype(np.float32)\n",
    "print('Data shape: ', x.shape)\n",
    "x = (x/255.) \n",
    "IMG_SHAPE = x[0,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(torch.nn.Module):\n",
    "    def __init__(self,nchannels, BIAS):\n",
    "        super(discriminator ,self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            \n",
    "        nn.Conv2d(in_channels=nchannels, out_channels=16, kernel_size=3, stride=1, padding=1, bias=BIAS),\n",
    "        nn.ELU(),\n",
    "            \n",
    "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1, bias=BIAS),\n",
    "        nn.ELU(),\n",
    "        nn.AvgPool2d(kernel_size=2),\n",
    "        \n",
    "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1, bias=BIAS),\n",
    "        nn.ELU(),        \n",
    "        \n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, bias=BIAS),\n",
    "        nn.ELU(),\n",
    "        nn.AvgPool2d(kernel_size=2),\n",
    "        \n",
    "        nn.Flatten(),\n",
    "        \n",
    "        nn.Linear( in_features = 4096 , out_features = 256, bias=BIAS),    \n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Linear( in_features = 256 , out_features = 2, bias=BIAS),\n",
    "        torch.nn.LogSoftmax()\n",
    "        )\n",
    "    \n",
    "    def forward(self,X):\n",
    "        return self.main(X)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape, batch_size=32):\n",
    "        super(Reshape ,self).__init__()\n",
    "        self.shape = shape\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view([x.size()[0], self.shape[0], self.shape[1], self.shape[2] ])\n",
    "    \n",
    "\n",
    "class generator(torch.nn.Module):\n",
    "    def __init__(self,code_size, BIAS):\n",
    "        super(generator ,self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "    \n",
    "        nn.Linear(code_size, 640),\n",
    "        Reshape((10,8,8)),\n",
    "            \n",
    "        torch.nn.ConvTranspose2d(in_channels=10, out_channels=64, kernel_size=5, stride=1, padding=0, bias=BIAS),\n",
    "        nn.ELU(),\n",
    "        \n",
    "        torch.nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=5, stride=1, padding=0, bias=BIAS),\n",
    "        nn.ELU(),\n",
    "        torch.nn.Upsample(scale_factor=2),\n",
    "        \n",
    "        torch.nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=0, bias=BIAS),\n",
    "        nn.ELU(),\n",
    "        \n",
    "        torch.nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=0, bias=BIAS),\n",
    "        nn.ELU(),\n",
    "        \n",
    "        torch.nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=0, bias=BIAS),\n",
    "        nn.ELU(),\n",
    "        \n",
    "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=0, bias=BIAS),\n",
    "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=0, bias=BIAS),\n",
    "        nn.Conv2d(in_channels=32, out_channels=3, kernel_size=3, stride=1, padding=0, bias=BIAS)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "disc = discriminator( IMG_SIZE, BIAS ).to(device)\n",
    "gen = generator( CODE_SIZE, BIAS ).to(device)\n",
    "summary(disc, IMG_SHAPE, batch_size=-1, device='cuda')\n",
    "summary(gen, (1,256), batch_size=-1, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(nrow=2,ncol=2):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        images = gen(torch.randn( (nrow*ncol, CODE_SIZE), dtype = torch.float32, device = device)).cpu().numpy()\n",
    "    images = np.moveaxis(images,1,3)\n",
    "    \n",
    "    if np.var(images)!=0:\n",
    "        images = images.clip(np.min(x),np.max(x))\n",
    "    \n",
    "    print('Sampled images:')\n",
    "    for i in range(nrow*ncol):\n",
    "        plt.subplot(nrow,ncol,i+1)\n",
    "        plt.imshow(images[i,:,:,:],cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "def sample_probas(bsize):\n",
    "    idx = np.random.choice(np.arange(x.shape[0]), size=bsize)\n",
    "    with torch.no_grad():\n",
    "        D_G_z = np.exp(disc(gen(torch.randn( (bsize, CODE_SIZE), dtype = torch.float32, device = device))).cpu().numpy()[:,1])\n",
    "        D_x = np.exp(disc(torch.Tensor(x[idx]).to(device)).cpu().numpy()[:,1])\n",
    "        \n",
    "    plt.title('Generated vs real data')\n",
    "    plt.hist(D_x,\n",
    "             label='D(x)', alpha=0.5,range=[0,1])\n",
    "    plt.hist(D_G_z,\n",
    "             label='D(G(z))',alpha=0.5,range=[0,1])\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = 0.9\n",
    "optimizerD = torch.optim.Adam(disc.parameters(), lr=1e-3, betas=(b1, 0.999))\n",
    "optimizerG = torch.optim.Adam(gen.parameters(), lr=1e-4, betas=(b1, 0.999))\n",
    "EPOCHS = 3000\n",
    "DISC_ITER = 5\n",
    "GEN_ITER = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    for i in range(DISC_ITER):\n",
    "        dderror=0\n",
    "        dgerror=0\n",
    "        idx = np.random.choice(np.arange(x.shape[0]), size=100)\n",
    "        optimizerD.zero_grad()\n",
    "        D_x = disc(torch.Tensor(x[idx,:,:,:]).to(device))\n",
    "        logp_real = -1*torch.mean(D_x[:,1]) +torch.mean(disc.main[-2]._parameters['weight'].data**2)+torch.mean(disc.main[-2]._parameters['bias'].data**2)\n",
    "        logp_real.backward()\n",
    "    \n",
    "        \n",
    "        code = torch.randn( (100, CODE_SIZE), dtype = torch.float32, device = device)\n",
    "        fake_img = gen(code).detach()\n",
    "        D_G_z = disc(fake_img.detach())\n",
    "        logp_gen = -1*torch.mean(D_G_z[:,0])\n",
    "        logp_gen.backward()\n",
    "        errD = (logp_gen + logp_real)\n",
    "        optimizerD.step()\n",
    "        dderror += logp_real.item()\n",
    "        dgerror += logp_gen.item()\n",
    "        \n",
    "        \n",
    "    for j in range(GEN_ITER):        \n",
    "        code = torch.randn( (100, CODE_SIZE), dtype = torch.float32, device = device)\n",
    "        gerror = 0\n",
    "        optimizerG.zero_grad()\n",
    "        fake_img = gen(code)\n",
    "        D_G_z = disc(fake_img)\n",
    "        logp_gen = -1*torch.mean(D_G_z[:,1])\n",
    "        logp_gen.backward()\n",
    "        optimizerG.step()\n",
    "        gerror += logp_gen.item()\n",
    "    \n",
    "        \n",
    "    \n",
    "    if epoch%50 == 0:\n",
    "        display.clear_output(wait=True)\n",
    "        idx = np.random.choice(np.arange(x.shape[0]), size=1000)\n",
    "        sample_images()\n",
    "        sample_probas(1000)\n",
    "        print('Current epoch: ', epoch)\n",
    "        print('Discriminator real data error: ', dderror)\n",
    "        print('Discriminator fake data error: ', dgerror)\n",
    "        print('Discriminator total error: ', dderror + dgerror)\n",
    "        print('Generator error: ', gerror)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(disc.state_dict(), PATH + '/My_Discriminator.pth')\n",
    "torch.save(gen.state_dict(), PATH + '/My_Generator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator(CODE_SIZE,BIAS).to(device)\n",
    "gen.load_state_dict(torch.load(PATH + '/My_Generator.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (36,36,3)\n",
    "sample_images(2,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
